{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "mpFaceMesh = mp.solutions.face_mesh\n",
    "faceMesh = mpFaceMesh.FaceMesh(max_num_faces = 2)\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "while True:\n",
    "    succes, img = cap.read()\n",
    "        \n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    result = faceMesh.process(imgRGB) \n",
    "    \n",
    "    if result.multi_face_landmarks:\n",
    "        for faceLms in result.multi_face_landmarks:\n",
    "            # Mostrar todos los puntos\n",
    "            mpDraw.draw_landmarks(img, faceLms, mpFaceMesh.FACEMESH_CONTOURS)\n",
    "            \n",
    "            # Mostrar solo el contorno\n",
    "            draw_spec = mpDraw.DrawingSpec(thickness=1, circle_radius=0)  \n",
    "            mpDraw.draw_landmarks(img, faceLms, mpFaceMesh.FACEMESH_CONTOURS, draw_spec, draw_spec)\n",
    "\n",
    "        \n",
    "    cv2.imshow(\"Image\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # Presionar 'Esc' para salir\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UBICAR UN PUNTO CONCRETO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "mpFaceMesh = mp.solutions.face_mesh\n",
    "faceMesh = mpFaceMesh.FaceMesh(max_num_faces = 2, refine_landmarks=True)\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "while True:\n",
    "    succes, img = cap.read()\n",
    "        \n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    result = faceMesh.process(imgRGB) \n",
    "    \n",
    "    if result.multi_face_landmarks:\n",
    "        for faceLms in result.multi_face_landmarks:\n",
    "            # Mostrar todos los puntos\n",
    "            #mpDraw.draw_landmarks(img, faceLms, mpFaceMesh.FACEMESH_CONTOURS)\n",
    "\n",
    "            # Pintar los puntos del iris\n",
    "            for id, lm in enumerate(faceLms.landmark): \n",
    "                h, w, c = img.shape\n",
    "                centerX, centerY = int(lm.x*w), int(lm.y*h)\n",
    "                \n",
    "                if id in [468, 473]: # Puntos del iris\n",
    "                    cv2.circle(img, (centerX, centerY), 3, (255,0,255), cv2.FILLED)\n",
    "\n",
    "        \n",
    "    cv2.imshow(\"Image\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # Presionar 'Esc' para salir\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguimiento de retina con el raton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "mpFaceMesh = mp.solutions.face_mesh\n",
    "faceMesh = mpFaceMesh.FaceMesh(max_num_faces=1, refine_landmarks=True)\n",
    "screen_w, screen_h = pyautogui.size()\n",
    "\n",
    "smooth_factor = 0.2\n",
    "previous_mouse_x, previous_mouse_y = screen_w // 2, screen_h // 2\n",
    "\n",
    "# Landmarks clave para el ojo derecho\n",
    "eye_right_outer = 33\n",
    "eye_right_inner = 133\n",
    "iris_center = 468\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        continue\n",
    "\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    result = faceMesh.process(imgRGB)\n",
    "\n",
    "    if result.multi_face_landmarks:\n",
    "        faceLms = result.multi_face_landmarks[0]\n",
    "        h, w, c = img.shape\n",
    "\n",
    "        # Obtener coordenadas de ojo y iris\n",
    "        eye_outer = faceLms.landmark[eye_right_outer]\n",
    "        eye_inner = faceLms.landmark[eye_right_inner]\n",
    "        iris = faceLms.landmark[iris_center]\n",
    "\n",
    "        # Pasar a pixeles\n",
    "        eye_outer_x, eye_outer_y = int(eye_outer.x * w), int(eye_outer.y * h)\n",
    "        eye_inner_x, eye_inner_y = int(eye_inner.x * w), int(eye_inner.y * h)\n",
    "        iris_x, iris_y = int(iris.x * w), int(iris.y * h)\n",
    "\n",
    "        # Centro del ojo\n",
    "        eye_center_x = (eye_outer_x + eye_inner_x) // 2\n",
    "        eye_center_y = (eye_outer_y + eye_inner_y) // 2\n",
    "\n",
    "        # Dibujo de referencia\n",
    "        cv2.circle(img, (iris_x, iris_y), 5, (0, 255, 255), cv2.FILLED)\n",
    "        cv2.circle(img, (eye_center_x, eye_center_y), 3, (0, 0, 255), cv2.FILLED)\n",
    "        cv2.line(img, (eye_outer_x, eye_outer_y), (eye_inner_x, eye_inner_y), (255, 0, 0), 1)\n",
    "\n",
    "        # Calcula posición relativa del iris al centro del ojo en un eje normalizado\n",
    "        eye_width = np.linalg.norm(np.array([eye_outer_x, eye_outer_y]) - np.array([eye_inner_x, eye_inner_y]))\n",
    "        rel_x = (eye_center_x - iris_x) / eye_width\n",
    "        rel_y = (eye_center_y - iris_y) / eye_width\n",
    "\n",
    "\n",
    "        # Ajustar sensibilidad\n",
    "        amplification_factor = 2.5  # Puedes ajustar este valor para hacerlo más o menos sensible\n",
    "\n",
    "        mapped_x = screen_w / 2 + rel_x * screen_w * amplification_factor\n",
    "        mapped_y = screen_h / 2 + rel_y * screen_h * amplification_factor\n",
    "\n",
    "        # Suavizado\n",
    "        smoothed_x = previous_mouse_x + (mapped_x - previous_mouse_x) * smooth_factor\n",
    "        smoothed_y = previous_mouse_y + (mapped_y - previous_mouse_y) * smooth_factor\n",
    "\n",
    "        pyautogui.moveTo(smoothed_x, smoothed_y)\n",
    "        previous_mouse_x, previous_mouse_y = smoothed_x, smoothed_y\n",
    "\n",
    "    cv2.imshow(\"Eye Tracking Localized - Right Iris (468)\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
